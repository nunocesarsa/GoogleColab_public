{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Testing multi task ANN_deep.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunocesarsa/GoogleColab_public/blob/master/Copy_of_Testing_multi_task_ANN_deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tRHGItMVz01",
        "colab_type": "text"
      },
      "source": [
        "Trying to implement a multi task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jjQzYFZveo7",
        "colab_type": "code",
        "outputId": "ffa3995f-29c9-4d90-e38d-0ff2ca8c4d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing packages\n",
        "\n",
        "#Needed for step 1 - data generation\n",
        "\n",
        "#Installing PROSAIL\n",
        "!pip install prosail\n",
        "\n",
        "#latin hypercube stuff\n",
        "#lets try to do a LHS\n",
        "!pip install lhsmdu\n",
        "\n",
        "#this package as a number of functions to deal with hyperspectral data\n",
        "!pip install pysptools\n",
        "\n",
        "#this is the swarm optimization package\n",
        "!pip install --upgrade pyswarm\n",
        "\n",
        "#spotpy\n",
        "!pip install spotpy\n",
        "\n",
        "#bayesian optimization packages\n",
        "!pip install bayesian-optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prosail\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/52/d0c15ab469e8c82bc76a6b6cd614efbc60e43d09d5bacaa349170d229e91/prosail-2.0.5-py3-none-any.whl (149kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from prosail) (0.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from prosail) (1.17.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from prosail) (3.6.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from prosail) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->prosail) (42.0.2)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->prosail) (0.31.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (8.0.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (19.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->prosail) (1.12.0)\n",
            "Installing collected packages: prosail\n",
            "Successfully installed prosail-2.0.5\n",
            "Collecting lhsmdu\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/f0/e714a4dae734bcd7228a09d74fff7dc5857dc3311cd72a3e07b09c85d088/lhsmdu-0.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lhsmdu) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lhsmdu) (1.4.1)\n",
            "Installing collected packages: lhsmdu\n",
            "Successfully installed lhsmdu-0.1\n",
            "Collecting pysptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/20/cef48129eff2bdcb282279138c09e6f04770a8fdcb3c1bb9a98fe4086d2d/pysptools-0.15.0.tar.gz (8.1MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1MB 5.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pysptools\n",
            "  Building wheel for pysptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptools: filename=pysptools-0.15.0-cp36-none-any.whl size=8133747 sha256=d56765b156d45c1caa38bd0a02f80a2cae5132773b7936f7a620e6491f08cc05\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/60/be/a6719d91bfa59135201feb034c7069e4146aa576fc0dc9e624\n",
            "Successfully built pysptools\n",
            "Installing collected packages: pysptools\n",
            "Successfully installed pysptools-0.15.0\n",
            "Collecting pyswarm\n",
            "  Downloading https://files.pythonhosted.org/packages/79/1e/254c108b5e65c65d57a83a9a448405ea8b6a6c5c10dada8bcab4e9d9a831/pyswarm-0.6.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyswarm) (1.17.5)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-cp36-none-any.whl size=4479 sha256=5e63b36d3edcb9e701327b1afd236a17af23c8801061e05e34e11e7a81fb9c5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/c5/f6/b33b9ac00040cb95c1f00af982a4197334a672d6de43f4699f\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n",
            "Collecting spotpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dd/db7c484b2150841655bc05954039428a390d36060dc85c27839b1a12fab7/spotpy-1.5.8-py3-none-any.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: spotpy\n",
            "Successfully installed spotpy-1.5.8\n",
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10032 sha256=3e7e3ffdbf10caede038666e5db809560e7c912d5f8ce452f9a8ddfa7d45404c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9c2-u71V45M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing packages\n",
        "\n",
        "#General purpose: \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#PROSPECT+SAIL Radiative transfer mode package\n",
        "import prosail\n",
        "\n",
        "#Sampling design package\n",
        "import lhsmdu\n",
        "\n",
        "#package to for operations on spectral data\n",
        "import pysptools as sptool \n",
        "from pysptools import distance\n",
        "#machine learning packages are imported later, nearer to the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9NBfqrwWE-k",
        "colab_type": "code",
        "outputId": "79f3d500-e89e-4153-b1f2-38aa94d86283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcJv5lp1Wdpe",
        "colab_type": "code",
        "outputId": "742731a1-a90a-4fe8-c992-7645d0617731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def custom_prosail(cab,cw,cm,lai):\n",
        "  import prosail\n",
        "  #default parameters\n",
        "  n= 1.\n",
        "  car=10.\n",
        "  cbrown=0.01\n",
        "  typelidf=1 #this is the default option\n",
        "  lidfa = -1 #leaf angle distribution parameter a and b\n",
        "  lidfb=-0.15\n",
        "  hspot= 0.01 #hotspot parameters - got this from R package https://www.rdocumentation.org/packages/hsdar/versions/0.4.1/topics/PROSAIL\n",
        "  #sun and viewing angle\n",
        "  tts=30. #observation and solar position parameters\n",
        "  tto=10. \n",
        "  psi=0.\n",
        "  #for now i put them by hand but they should be an input of a custom function\n",
        "  #tts=sol_zen #solar zenith angle\n",
        "  #tto=inc_zen #sensor zenith angle\n",
        "  #psi=raa\n",
        "  rho_out = prosail.run_prosail(n,\n",
        "                                 cab,\n",
        "                                 car,\n",
        "                                 cbrown,\n",
        "                                 cw,\n",
        "                                 cm,\n",
        "                                 lai,\n",
        "                                 lidfa,\n",
        "                                 hspot,\n",
        "                                 tts,tto,psi,\n",
        "                                 typelidf, lidfb,\n",
        "                                 prospect_version=\"D\",\n",
        "                                 factor='SDR', \n",
        "                                 rsoil=.1, psoil=.5)\n",
        "  return(rho_out)\n",
        "\n",
        "#test call:\n",
        "custom_prosail(40,.005,.005,2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02147451, 0.02147321, 0.02147204, ..., 0.02853143, 0.02829189,\n",
              "       0.02836254])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsW4q-DhV7Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Prosail2S2(path2csv,spectra_input):\n",
        "  #importing pandas\n",
        "  import pandas as pd\n",
        "  import numpy\n",
        "  import numpy as np\n",
        "  #upload a S2_Response.csv from https://earth.esa.int/web/sentinel/user-guides/sentinel-2-msi/document-library/-/asset_publisher/Wk0TKajiISaR/content/sentinel-2a-spectral-responses\n",
        "\n",
        "  s2_table = pd.read_csv(path2csv,sep=\";\",decimal=\",\") #check if this is proper, regarding the sep and dec\n",
        "\n",
        "  s2_table_sel = s2_table[s2_table['SR_WL'].between(400,2500)] #selects all values between 400 and 2500\n",
        "  spectra_input_df = pd.DataFrame(data=spectra_input,columns=[\"rho\"],index=s2_table_sel.index) #transforms the input array into a pandas df with the column name rho and row.index = to the original input table\n",
        "\n",
        "  \n",
        "  rho_s2 = s2_table_sel.multiply(spectra_input_df['rho'],axis=\"index\") #calculates the numerator\n",
        "  w_band_sum = s2_table_sel.sum(axis=0,skipna = True) #calculates the denominator\n",
        "\n",
        "  output = (rho_s2.sum(axis=0)/w_band_sum).rename_axis(\"ID\").values #runs the weighted mean and converts the output to a numpy array\n",
        "\n",
        "  return output[1:] #removes the first value because it represents the wavelength column\n",
        "\n",
        "\n",
        "#please LOAD THTE FILE NOW\n",
        "filepath=\"/content/S2_Response.csv\"\n",
        "#filepath=\"/content/S2_Responses_S2B.csv\"\n",
        "filepath=\"/content/drive/My Drive/S2_Response.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJDNsy00WatF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Gen_spectra_data(traits):\n",
        "  k = 1\n",
        "  #pd_train_traits=traits\n",
        "  #print(range(len(traits)))\n",
        "  for i in range(len(traits)):\n",
        "    #n_t = pd_train_traits[\"n\"][i]\n",
        "    cab_t = traits[\"cab\"][i]\n",
        "    #car_t = pd_train_traits[\"car\"][i]\n",
        "    #cbrown_t = pd_train_traits[\"cbrown\"][i]\n",
        "    cw_t = traits[\"cw\"][i]\n",
        "    cm_t = traits[\"cm\"][i]\n",
        "    lai_t = traits[\"lai\"][i]\n",
        "\n",
        "    if k == 1:\n",
        "      tr_rho_s = custom_prosail(cab_t,cw_t,cm_t,lai_t)\n",
        "      tr_rho_s = Prosail2S2(filepath,tr_rho_s)\n",
        "      #plt.plot ( x, tr_rho_s, ':', label=\"Training prosail\")\n",
        "      #plt.legend(loc='best')\n",
        "      \n",
        "    if k > 1:\n",
        "      tr_rho_t = custom_prosail(cab_t,cw_t,cm_t,lai_t)\n",
        "      tr_rho_t = Prosail2S2(filepath,tr_rho_t)\n",
        "      tr_rho_s = np.vstack((tr_rho_s,tr_rho_t))\n",
        "      #plt.plot ( x, tr_rho_t, ':')\n",
        "\n",
        "    k = k+1\n",
        "\n",
        "\n",
        "  rho_samples=tr_rho_s\n",
        "\n",
        "\n",
        "  return rho_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7qUbEF5Woy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#number of samples\n",
        "train_n3000 = 10000\n",
        "\n",
        "n_traits=4 #I will test on 4 varying traits: cab, car, cw,cm,lai\n",
        "\n",
        "#generating a LHS hypercube (it uses a 0 to 1 interval that can be used as a multiplier against the different traits)\n",
        "np.random.seed(0)\n",
        "LHS_train3000 = lhsmdu.createRandomStandardUniformMatrix(n_traits,train_n3000 ) #the package has a more advanced method but it is too slow to process\n",
        "\n",
        "#maxmins from here also: https://github.com/jgomezdans/prosail/issues/10\n",
        "\n",
        "#max_n=1 #this value should go from 1 to 2, so i make it change from 0 to 1 here and then add 1 later\n",
        "max_cab=90. #add 1\n",
        "#max_car=44. #add 1\n",
        "#max_cbrown= 9.99 #add 0.01\n",
        "max_cw=0.0039 #0.008 #add 0.001 \n",
        "max_cm=0.0039 #0.008 #0.001\n",
        "max_lai = 6 #add 0.1\n",
        "\n",
        "\n",
        "min_cab = 10.\n",
        "min_cw = 0.002\n",
        "min_cm = 0.002\n",
        "min_lai = .5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzdYx9NcWsfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing function inputs\n",
        "\n",
        "\n",
        "pd_traits3000 = pd.DataFrame.transpose(pd.DataFrame(LHS_train3000))\n",
        "pd_traits3000.columns = [\"cab\",\"cw\",\"cm\",\"lai\"]\n",
        "\n",
        "pd_traits3000[\"cab\"]=pd_traits3000[\"cab\"]*max_cab+min_cab\n",
        "pd_traits3000[\"cw\"] =pd_traits3000[\"cw\"] *max_cw +min_cw\n",
        "pd_traits3000[\"cm\"] =pd_traits3000[\"cm\"] *max_cm +min_cm\n",
        "pd_traits3000[\"lai\"]=pd_traits3000[\"lai\"]*max_lai+min_lai\n",
        "\n",
        "np_spectra3000 = Gen_spectra_data(pd_traits3000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL9-VWy7fjnH",
        "colab_type": "code",
        "outputId": "dcc11709-953b-4bd6-e66a-f1e17e32a396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(pd_traits3000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            cab        cw        cm       lai\n",
            "0     59.393215  0.003614  0.003462  4.320172\n",
            "1     74.367043  0.004456  0.003672  5.900273\n",
            "2     64.248704  0.005036  0.004664  5.143716\n",
            "3     59.039486  0.005321  0.004344  1.273192\n",
            "4     48.128932  0.005184  0.002275  0.899944\n",
            "...         ...       ...       ...       ...\n",
            "2995  94.751836  0.002407  0.004002  3.490882\n",
            "2996  59.151947  0.002544  0.002282  1.230570\n",
            "2997  39.125234  0.004716  0.002270  5.560886\n",
            "2998  83.219052  0.003886  0.004956  6.157456\n",
            "2999  72.766034  0.003324  0.005635  5.496935\n",
            "\n",
            "[3000 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucr5wSwjZuff",
        "colab_type": "code",
        "outputId": "3e263985-814a-438c-e7b4-9ce07e8333b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#band order\n",
        "#['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10''B11','B12']\n",
        "#['B2','B3','B4','B5','B6','B7','B8A','B11','B12']\n",
        "\n",
        "#print(np_spectra3000.shape)\n",
        "#lets also create a numpy object for the tratis\n",
        "np_traits3000 = pd_traits3000.iloc[:,:].values\n",
        "\n",
        "train_df_3000 = np_spectra3000[:,[1,2,3,4,5,6,8,11,12]]\n",
        "print(train_df_3000.shape)\n",
        "\n",
        "X_train = train_df_3000\n",
        "Y_train = np_traits3000"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNrSRspDXC2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "8427c950-e368-43ac-cc08-9b0e17eed28a"
      },
      "source": [
        "#machine learning stuff\n",
        "from sklearn.neural_network import MLPRegressor as ANN_reg #this is a simpler neural network package\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK0jyn6ifHU_",
        "colab_type": "text"
      },
      "source": [
        "https://keras.io/getting-started/functional-api-guide/\n",
        "\n",
        "https://stackoverflow.com/questions/48615003/multi-task-learning-in-keras\n",
        "\n",
        "https://datascience.stackexchange.com/questions/27498/multi-task-learning-in-keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szQ_Nee5Xi0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#not multi task\n",
        "singl_ann = Sequential()\n",
        "singl_ann.add(Dense(10, input_dim=9, activation='tanh'))\n",
        "singl_ann.add(Dense(6, input_dim=9, activation='relu'))\n",
        "singl_ann.add(Dense(4, input_dim=9, activation='linear'))\n",
        "\n",
        "singl_ann.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#multi tas\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "inputs = Input(shape=(9,))\n",
        "sub1 = Dense(64, activation='tanh')(inputs)\n",
        "sub2 = Dense(32, activation='tanh')(sub1)\n",
        "cab1 = Dense(16, activation='sigmoid')(sub2)\n",
        "cw1  = Dense(16, activation='sigmoid')(sub2)\n",
        "cm1  = Dense(16, activation='sigmoid')(sub2)\n",
        "lai1 = Dense(16, activation='sigmoid')(sub2)\n",
        "cab2 = Dense(1, activation='linear')(cab1)\n",
        "cw2  = Dense(1, activation='linear')(cw1)\n",
        "cm2  = Dense(1, activation='linear')(cm1)\n",
        "lai2 = Dense(1, activation='linear')(lai1)\n",
        "\n",
        "\n",
        "#building the model using keras api\n",
        "model = Model(inputs=inputs, outputs=[cab2,cw2,cm2,lai2])\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEfBCrWEgziX",
        "colab_type": "code",
        "outputId": "9f8b667b-ae83-4295-cbb8-eef61c33f32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#fitting the data, ANN needs standardization\n",
        "from sklearn.preprocessing import MinMaxScaler #this is to standardize the input data [not used for now]\n",
        "\n",
        "X_ann = X_train \n",
        "Y_ann = Y_train  #converts from a panda table to a numpy\n",
        "\n",
        "scaler = MinMaxScaler()#lets rescale the input\n",
        "scaler.fit(Y_ann)\n",
        "Y_ann_norm = scaler.transform(Y_ann)\n",
        "\n",
        "Y_ann_norm.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGAWUsFMiARF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA3TQjX5izL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cab_train = Y_ann_norm[:,0]\n",
        "cw_train = Y_ann_norm[:,1]\n",
        "cm_train = Y_ann_norm[:,2]\n",
        "lai_train = Y_ann_norm[:,3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27HpcGpFhSTP",
        "colab_type": "code",
        "outputId": "62a1d6a8-56b6-45c3-f5f9-621f25f45af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_ann,[cab_train,cw_train,cm_train,lai_train],epochs=100) #this hides the output spam\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 2s 199us/step - loss: 0.3378 - dense_75_loss: 0.1302 - dense_76_loss: 0.0894 - dense_77_loss: 0.0837 - dense_78_loss: 0.0346 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 0.0000e+00 - dense_78_acc: 2.0000e-04\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.1483 - dense_75_loss: 0.0223 - dense_76_loss: 0.0485 - dense_77_loss: 0.0660 - dense_78_loss: 0.0115 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.1151 - dense_75_loss: 0.0124 - dense_76_loss: 0.0337 - dense_77_loss: 0.0586 - dense_78_loss: 0.0104 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.1094 - dense_75_loss: 0.0094 - dense_76_loss: 0.0334 - dense_77_loss: 0.0566 - dense_78_loss: 0.0099 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.1045 - dense_75_loss: 0.0068 - dense_76_loss: 0.0335 - dense_77_loss: 0.0547 - dense_78_loss: 0.0095 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0969 - dense_75_loss: 0.0047 - dense_76_loss: 0.0328 - dense_77_loss: 0.0501 - dense_78_loss: 0.0092 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 1.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0856 - dense_75_loss: 0.0034 - dense_76_loss: 0.0306 - dense_77_loss: 0.0425 - dense_78_loss: 0.0090 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 1s 66us/step - loss: 0.0683 - dense_75_loss: 0.0025 - dense_76_loss: 0.0259 - dense_77_loss: 0.0316 - dense_78_loss: 0.0083 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0509 - dense_75_loss: 0.0020 - dense_76_loss: 0.0209 - dense_77_loss: 0.0208 - dense_78_loss: 0.0072 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0403 - dense_75_loss: 0.0014 - dense_76_loss: 0.0168 - dense_77_loss: 0.0166 - dense_78_loss: 0.0056 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0322 - dense_75_loss: 9.9017e-04 - dense_76_loss: 0.0133 - dense_77_loss: 0.0139 - dense_78_loss: 0.0040 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 1s 65us/step - loss: 0.0276 - dense_75_loss: 8.7061e-04 - dense_76_loss: 0.0108 - dense_77_loss: 0.0128 - dense_78_loss: 0.0031 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0250 - dense_75_loss: 7.9993e-04 - dense_76_loss: 0.0092 - dense_77_loss: 0.0123 - dense_78_loss: 0.0026 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0222 - dense_75_loss: 7.1691e-04 - dense_76_loss: 0.0077 - dense_77_loss: 0.0115 - dense_78_loss: 0.0023 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0214 - dense_75_loss: 6.5700e-04 - dense_76_loss: 0.0070 - dense_77_loss: 0.0114 - dense_78_loss: 0.0023 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0194 - dense_75_loss: 5.8229e-04 - dense_76_loss: 0.0061 - dense_77_loss: 0.0105 - dense_78_loss: 0.0022 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0174 - dense_75_loss: 5.4308e-04 - dense_76_loss: 0.0052 - dense_77_loss: 0.0095 - dense_78_loss: 0.0022 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0166 - dense_75_loss: 4.9273e-04 - dense_76_loss: 0.0050 - dense_77_loss: 0.0091 - dense_78_loss: 0.0021 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0157 - dense_75_loss: 4.5702e-04 - dense_76_loss: 0.0046 - dense_77_loss: 0.0085 - dense_78_loss: 0.0021 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0146 - dense_75_loss: 4.1960e-04 - dense_76_loss: 0.0044 - dense_77_loss: 0.0077 - dense_78_loss: 0.0021 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0134 - dense_75_loss: 3.8427e-04 - dense_76_loss: 0.0040 - dense_77_loss: 0.0069 - dense_78_loss: 0.0021 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0125 - dense_75_loss: 3.6398e-04 - dense_76_loss: 0.0037 - dense_77_loss: 0.0063 - dense_78_loss: 0.0021 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0115 - dense_75_loss: 3.3358e-04 - dense_76_loss: 0.0035 - dense_77_loss: 0.0057 - dense_78_loss: 0.0020 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 1s 66us/step - loss: 0.0117 - dense_75_loss: 3.1891e-04 - dense_76_loss: 0.0036 - dense_77_loss: 0.0057 - dense_78_loss: 0.0020 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0102 - dense_75_loss: 2.9373e-04 - dense_76_loss: 0.0031 - dense_77_loss: 0.0049 - dense_78_loss: 0.0019 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0101 - dense_75_loss: 2.8230e-04 - dense_76_loss: 0.0031 - dense_77_loss: 0.0047 - dense_78_loss: 0.0020 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 1s 74us/step - loss: 0.0094 - dense_75_loss: 2.5500e-04 - dense_76_loss: 0.0029 - dense_77_loss: 0.0043 - dense_78_loss: 0.0019 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0092 - dense_75_loss: 2.4070e-04 - dense_76_loss: 0.0028 - dense_77_loss: 0.0042 - dense_78_loss: 0.0019 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0082 - dense_75_loss: 2.1798e-04 - dense_76_loss: 0.0025 - dense_77_loss: 0.0037 - dense_78_loss: 0.0018 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0085 - dense_75_loss: 1.9728e-04 - dense_76_loss: 0.0027 - dense_77_loss: 0.0039 - dense_78_loss: 0.0018 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0075 - dense_75_loss: 1.7922e-04 - dense_76_loss: 0.0023 - dense_77_loss: 0.0034 - dense_78_loss: 0.0017 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0073 - dense_75_loss: 1.7374e-04 - dense_76_loss: 0.0021 - dense_77_loss: 0.0032 - dense_78_loss: 0.0017 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0070 - dense_75_loss: 1.5636e-04 - dense_76_loss: 0.0021 - dense_77_loss: 0.0031 - dense_78_loss: 0.0016 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0067 - dense_75_loss: 1.4252e-04 - dense_76_loss: 0.0020 - dense_77_loss: 0.0030 - dense_78_loss: 0.0016 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0062 - dense_75_loss: 1.2659e-04 - dense_76_loss: 0.0018 - dense_77_loss: 0.0027 - dense_78_loss: 0.0015 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0060 - dense_75_loss: 1.1501e-04 - dense_76_loss: 0.0017 - dense_77_loss: 0.0026 - dense_78_loss: 0.0015 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0056 - dense_75_loss: 1.0727e-04 - dense_76_loss: 0.0016 - dense_77_loss: 0.0024 - dense_78_loss: 0.0015 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 1s 63us/step - loss: 0.0053 - dense_75_loss: 1.0578e-04 - dense_76_loss: 0.0015 - dense_77_loss: 0.0023 - dense_78_loss: 0.0014 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 1s 64us/step - loss: 0.0052 - dense_75_loss: 9.0738e-05 - dense_76_loss: 0.0015 - dense_77_loss: 0.0022 - dense_78_loss: 0.0014 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0051 - dense_75_loss: 8.6867e-05 - dense_76_loss: 0.0015 - dense_77_loss: 0.0022 - dense_78_loss: 0.0013 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0053 - dense_75_loss: 8.0903e-05 - dense_76_loss: 0.0016 - dense_77_loss: 0.0024 - dense_78_loss: 0.0013 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0044 - dense_75_loss: 6.8738e-05 - dense_76_loss: 0.0013 - dense_77_loss: 0.0019 - dense_78_loss: 0.0012 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0047 - dense_75_loss: 6.8096e-05 - dense_76_loss: 0.0014 - dense_77_loss: 0.0020 - dense_78_loss: 0.0012 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0041 - dense_75_loss: 6.0744e-05 - dense_76_loss: 0.0012 - dense_77_loss: 0.0017 - dense_78_loss: 0.0011 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0037 - dense_75_loss: 5.5407e-05 - dense_76_loss: 0.0011 - dense_77_loss: 0.0016 - dense_78_loss: 0.0011 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0037 - dense_75_loss: 5.3218e-05 - dense_76_loss: 0.0011 - dense_77_loss: 0.0016 - dense_78_loss: 9.7897e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0039 - dense_75_loss: 4.7020e-05 - dense_76_loss: 0.0012 - dense_77_loss: 0.0017 - dense_78_loss: 9.4590e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0036 - dense_75_loss: 4.3496e-05 - dense_76_loss: 0.0011 - dense_77_loss: 0.0016 - dense_78_loss: 8.9128e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0041 - dense_75_loss: 4.3258e-05 - dense_76_loss: 0.0013 - dense_77_loss: 0.0019 - dense_78_loss: 8.8488e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0035 - dense_75_loss: 3.8172e-05 - dense_76_loss: 0.0011 - dense_77_loss: 0.0016 - dense_78_loss: 8.0791e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0032 - dense_75_loss: 3.6018e-05 - dense_76_loss: 9.7117e-04 - dense_77_loss: 0.0014 - dense_78_loss: 7.8920e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 0.0029 - dense_75_loss: 3.4334e-05 - dense_76_loss: 8.4369e-04 - dense_77_loss: 0.0012 - dense_78_loss: 7.3204e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0029 - dense_75_loss: 3.2475e-05 - dense_76_loss: 8.5338e-04 - dense_77_loss: 0.0013 - dense_78_loss: 7.2355e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0029 - dense_75_loss: 3.1093e-05 - dense_76_loss: 8.5981e-04 - dense_77_loss: 0.0013 - dense_78_loss: 6.6987e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0026 - dense_75_loss: 3.1833e-05 - dense_76_loss: 7.9745e-04 - dense_77_loss: 0.0012 - dense_78_loss: 6.2071e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0026 - dense_75_loss: 3.0789e-05 - dense_76_loss: 8.0357e-04 - dense_77_loss: 0.0012 - dense_78_loss: 6.0513e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0022 - dense_75_loss: 2.8376e-05 - dense_76_loss: 6.3310e-04 - dense_77_loss: 9.5404e-04 - dense_78_loss: 5.5376e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0025 - dense_75_loss: 2.8457e-05 - dense_76_loss: 7.4680e-04 - dense_77_loss: 0.0011 - dense_78_loss: 5.5585e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0026 - dense_75_loss: 2.8106e-05 - dense_76_loss: 8.0088e-04 - dense_77_loss: 0.0012 - dense_78_loss: 5.2391e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0022 - dense_75_loss: 2.8221e-05 - dense_76_loss: 6.6366e-04 - dense_77_loss: 0.0010 - dense_78_loss: 4.6388e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0021 - dense_75_loss: 2.6198e-05 - dense_76_loss: 6.4166e-04 - dense_77_loss: 0.0010 - dense_78_loss: 4.5201e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0023 - dense_75_loss: 2.4304e-05 - dense_76_loss: 7.0221e-04 - dense_77_loss: 0.0011 - dense_78_loss: 4.4942e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.0025 - dense_75_loss: 2.5033e-05 - dense_76_loss: 7.8574e-04 - dense_77_loss: 0.0012 - dense_78_loss: 4.4108e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0021 - dense_75_loss: 2.4032e-05 - dense_76_loss: 6.4615e-04 - dense_77_loss: 9.9347e-04 - dense_78_loss: 4.2931e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0019 - dense_75_loss: 2.2283e-05 - dense_76_loss: 5.5597e-04 - dense_77_loss: 9.0662e-04 - dense_78_loss: 3.9394e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 1s 74us/step - loss: 0.0018 - dense_75_loss: 2.1258e-05 - dense_76_loss: 5.2953e-04 - dense_77_loss: 8.7232e-04 - dense_78_loss: 3.6394e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 0.0022 - dense_75_loss: 2.3931e-05 - dense_76_loss: 6.8721e-04 - dense_77_loss: 0.0011 - dense_78_loss: 3.7359e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0017 - dense_75_loss: 2.2864e-05 - dense_76_loss: 5.0272e-04 - dense_77_loss: 8.1625e-04 - dense_78_loss: 3.4584e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0016 - dense_75_loss: 1.9930e-05 - dense_76_loss: 4.7480e-04 - dense_77_loss: 7.9869e-04 - dense_78_loss: 2.9317e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0019 - dense_75_loss: 2.0016e-05 - dense_76_loss: 6.0004e-04 - dense_77_loss: 9.7901e-04 - dense_78_loss: 3.3917e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 1s 75us/step - loss: 0.0016 - dense_75_loss: 2.0591e-05 - dense_76_loss: 4.6771e-04 - dense_77_loss: 7.7621e-04 - dense_78_loss: 3.1449e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 0.0016 - dense_75_loss: 2.0669e-05 - dense_76_loss: 4.9387e-04 - dense_77_loss: 8.2146e-04 - dense_78_loss: 2.9769e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0016 - dense_75_loss: 1.8647e-05 - dense_76_loss: 5.0104e-04 - dense_77_loss: 8.2796e-04 - dense_78_loss: 2.6421e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0015 - dense_75_loss: 1.8209e-05 - dense_76_loss: 4.6634e-04 - dense_77_loss: 7.7741e-04 - dense_78_loss: 2.5542e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0017 - dense_75_loss: 1.8568e-05 - dense_76_loss: 5.1713e-04 - dense_77_loss: 8.7877e-04 - dense_78_loss: 2.5944e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0013 - dense_75_loss: 1.8332e-05 - dense_76_loss: 3.9524e-04 - dense_77_loss: 6.7450e-04 - dense_78_loss: 2.3474e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0013 - dense_75_loss: 1.7098e-05 - dense_76_loss: 3.7547e-04 - dense_77_loss: 6.4730e-04 - dense_78_loss: 2.3677e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0013 - dense_75_loss: 1.8874e-05 - dense_76_loss: 3.9439e-04 - dense_77_loss: 6.7699e-04 - dense_78_loss: 2.1482e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0011 - dense_75_loss: 1.6849e-05 - dense_76_loss: 3.2787e-04 - dense_77_loss: 5.8546e-04 - dense_78_loss: 2.0556e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0012 - dense_75_loss: 1.8344e-05 - dense_76_loss: 3.4593e-04 - dense_77_loss: 5.9354e-04 - dense_78_loss: 2.3021e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0015 - dense_75_loss: 1.7984e-05 - dense_76_loss: 4.9141e-04 - dense_77_loss: 7.9970e-04 - dense_78_loss: 2.1493e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 1s 69us/step - loss: 0.0013 - dense_75_loss: 1.7552e-05 - dense_76_loss: 4.1183e-04 - dense_77_loss: 6.7666e-04 - dense_78_loss: 2.2106e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0013 - dense_75_loss: 1.7298e-05 - dense_76_loss: 3.8866e-04 - dense_77_loss: 6.5320e-04 - dense_78_loss: 2.0913e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 1s 72us/step - loss: 0.0014 - dense_75_loss: 1.6184e-05 - dense_76_loss: 4.5069e-04 - dense_77_loss: 7.2855e-04 - dense_78_loss: 2.2557e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 0.0014 - dense_75_loss: 1.5920e-05 - dense_76_loss: 4.6063e-04 - dense_77_loss: 7.6212e-04 - dense_78_loss: 2.0023e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 1s 66us/step - loss: 0.0011 - dense_75_loss: 1.5698e-05 - dense_76_loss: 3.3911e-04 - dense_77_loss: 5.7745e-04 - dense_78_loss: 1.7371e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0011 - dense_75_loss: 1.5707e-05 - dense_76_loss: 3.2674e-04 - dense_77_loss: 5.6198e-04 - dense_78_loss: 1.7066e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.0012 - dense_75_loss: 1.4117e-05 - dense_76_loss: 3.5543e-04 - dense_77_loss: 5.9777e-04 - dense_78_loss: 1.8634e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 1s 66us/step - loss: 0.0011 - dense_75_loss: 1.4775e-05 - dense_76_loss: 3.4816e-04 - dense_77_loss: 5.5908e-04 - dense_78_loss: 1.6328e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 0.0012 - dense_75_loss: 1.5431e-05 - dense_76_loss: 3.6198e-04 - dense_77_loss: 5.8749e-04 - dense_78_loss: 1.9511e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 9.1317e-04 - dense_75_loss: 1.3130e-05 - dense_76_loss: 2.7493e-04 - dense_77_loss: 4.7273e-04 - dense_78_loss: 1.5239e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 9.9580e-04 - dense_75_loss: 1.4150e-05 - dense_76_loss: 3.0498e-04 - dense_77_loss: 5.1114e-04 - dense_78_loss: 1.6553e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.0011 - dense_75_loss: 1.4012e-05 - dense_76_loss: 3.4948e-04 - dense_77_loss: 5.7162e-04 - dense_78_loss: 1.8199e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 8.0071e-04 - dense_75_loss: 1.3845e-05 - dense_76_loss: 2.3441e-04 - dense_77_loss: 4.0335e-04 - dense_78_loss: 1.4911e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 1s 74us/step - loss: 0.0012 - dense_75_loss: 1.5265e-05 - dense_76_loss: 3.8898e-04 - dense_77_loss: 6.3104e-04 - dense_78_loss: 2.0589e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 1s 65us/step - loss: 9.2223e-04 - dense_75_loss: 1.3630e-05 - dense_76_loss: 2.8712e-04 - dense_77_loss: 4.7011e-04 - dense_78_loss: 1.5137e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 1s 70us/step - loss: 8.6702e-04 - dense_75_loss: 1.6069e-05 - dense_76_loss: 2.6879e-04 - dense_77_loss: 4.5179e-04 - dense_78_loss: 1.3037e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 8.0119e-04 - dense_75_loss: 1.2218e-05 - dense_76_loss: 2.4528e-04 - dense_77_loss: 4.1876e-04 - dense_78_loss: 1.2493e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 8.5552e-04 - dense_75_loss: 1.3432e-05 - dense_76_loss: 2.5933e-04 - dense_77_loss: 4.3696e-04 - dense_78_loss: 1.4579e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 1s 73us/step - loss: 8.7654e-04 - dense_75_loss: 1.4480e-05 - dense_76_loss: 2.7004e-04 - dense_77_loss: 4.4556e-04 - dense_78_loss: 1.4645e-04 - dense_75_acc: 2.0000e-04 - dense_76_acc: 2.0000e-04 - dense_77_acc: 2.0000e-04 - dense_78_acc: 2.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79687dcda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qDb2_ImN2u",
        "colab_type": "code",
        "outputId": "14e32f8a-b285-4707-8a04-577872120d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "LHS_valid0500 = lhsmdu.createRandomStandardUniformMatrix(n_traits,500) #the package has a more advanced method but it is too slow to process\n",
        "\n",
        "\n",
        "pd_valid0500 = pd.DataFrame.transpose(pd.DataFrame(LHS_valid0500))\n",
        "pd_valid0500.columns = [\"cab\",\"cw\",\"cm\",\"lai\"]\n",
        "\n",
        "pd_valid0500[\"cab\"]=pd_valid0500[\"cab\"]*max_cab+min_cab\n",
        "pd_valid0500[\"cw\"] =pd_valid0500[\"cw\"] *max_cw +min_cw\n",
        "pd_valid0500[\"cm\"] =pd_valid0500[\"cm\"] *max_cm +min_cm\n",
        "pd_valid0500[\"lai\"]=pd_valid0500[\"lai\"]*max_lai+min_lai\n",
        "\n",
        "np_spectra0500 = Gen_spectra_data(pd_valid0500)\n",
        "\n",
        "print(np_spectra0500.shape)\n",
        "#lets also create a numpy object for the tratis\n",
        "np_valid0500 = pd_valid0500.iloc[:,:].values\n",
        "\n",
        "valid_df_0500 = np_spectra0500[:,[1,2,3,4,5,6,8,11,12]]\n",
        "print(valid_df_0500.shape)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 13)\n",
            "(500, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgOD_krzmaN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_ann_pred = model.predict(valid_df_0500)\n",
        "\n",
        "#lets assume this is the order\n",
        "cab_pred = Y_ann_pred[0]\n",
        "cw_pred  = Y_ann_pred[1]\n",
        "cm_pred  = Y_ann_pred[2]\n",
        "lai_pred = Y_ann_pred[3]\n",
        "\n",
        "np_Y_ann_pred = np.array(cab_pred)\n",
        "np_Y_ann_pred = np.hstack((np_Y_ann_pred,cw_pred))\n",
        "np_Y_ann_pred = np.hstack((np_Y_ann_pred,cm_pred))\n",
        "np_Y_ann_pred = np.hstack((np_Y_ann_pred,lai_pred))\n",
        "np_Y_ann_pred.shape\n",
        "\n",
        "#and finall we can re-transform the values\n",
        "np_Y_ann_pred = scaler.inverse_transform(np_Y_ann_pred)\n",
        "#np_Y_ann_pred\n",
        "\n",
        "#Y_ann_pred = pd.DataFrame(scaler.inverse_transform(model.predict(valid_df_0500)))\n",
        "#Y_ann_pred.columns = [\"cab\",\"car\",\"cw\",\"cm\"]\n",
        "#Y_ann_pred\n",
        "\n",
        "test_pred=np_Y_ann_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCD97BwgmvP-",
        "colab_type": "code",
        "outputId": "9d04bbf6-0373-4b58-f596-40567c4007b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "\n",
        "\n",
        "#plotting cab\n",
        "fig, axs = plt.subplots(1,2)\n",
        "fig.suptitle('Selected traits')\n",
        "fig.subplots_adjust(wspace=1)\n",
        "\n",
        "#plt.subplot(3,1,1)\n",
        "axs[0].plot(pd_valid0500[\"cab\"],test_pred[:,0],\"o\",label=\"Cab\")\n",
        "axs[0].legend(loc=\"upper left\")\n",
        "axs[0].set_ylabel(\"Prediction\")\n",
        "\n",
        "axs[1].plot(pd_valid0500[\"cw\"],test_pred[:,1],\"o\",label=\"Cw\")\n",
        "axs[1].legend(loc=\"upper left\")\n",
        "#axs[1].set_ylabel(\"Prediction\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#plotting cab\n",
        "fig, axs = plt.subplots(1,2)\n",
        "fig.suptitle('Selected traits')\n",
        "fig.subplots_adjust(wspace=1)\n",
        "\n",
        "\n",
        "axs[0].plot(pd_valid0500[\"cm\"],test_pred[:,2],\"o\",label=\"Cm\")\n",
        "axs[0].legend(loc=\"upper left\")\n",
        "#axs[0].set_ylabel(\"Prediction\")\n",
        "\n",
        "axs[1].plot(pd_valid0500[\"lai\"],test_pred[:,3],\"o\",label=\"LAI\")\n",
        "axs[1].legend(loc=\"upper left\")\n",
        "#axs[3].set_ylabel(\"Prediction\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEVCAYAAADOwrOnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBfEA4pxzriAeQJxzzhXk/wJHwtwg02muIAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7967af6b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEVCAYAAADkckIIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/zohDgZx8anpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}